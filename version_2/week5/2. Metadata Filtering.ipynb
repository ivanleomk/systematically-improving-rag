{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Week 5: Systematically Improving Your RAG Application\n",
    "\n",
    "> **Note:** Please walk through the previous notebook 1. Generate Dataset.ipynb first. If you haven't generated the dataset, please run `1. Generate Dataset.ipynb` first.\n",
    "\n",
    "# Why Use LLM Metadata\n",
    "\n",
    "As user queries become more complex, it becomes increasingly important to extract specific criteria that user queries need. To do so, we need to use query understanding to extract and map user queries to specific filters we support.\n",
    "\n",
    "Let's take the simple example of - I want a medium-sized black cotton T-shirt under $50. This requires multiple criterias to be extracted - size, material and price. In order to be able to do so, we need to have the indexes and data that support these filters.\n",
    "\n",
    "In this notebook, we'll explore how we can do so with structured extraction - both to generate metadata with LLMs and to map user queries to a list of predefined filters. We'll do so in 3 steps\n",
    "\n",
    "1. **Limitations of Semantic Search**: We'll start by loading in our dataset into a local LanceDB database and demonstrate how semantic search falls short for this task.\n",
    "\n",
    "2. **LLM Metadata Generation**: We'll then explore how we can use language models to generate metadata for our dataset to support a new filter type.\n",
    "\n",
    "3. **Query Understanding**: Lastly, we'll implement some query understanding to extract relevant filters from user queries and apply them to our retrieved items.\n",
    "\n",
    "We'll compare the results of semantic search against our retrieval pipeline when we use query understanding and LLM metadata filtering and see it's impact on retrieval evals like recall and mrr.\n",
    "\n",
    "This will allow us to understand how combining semantic search with structured metadata filtering leads to more accurate and useful recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations Of Semantic Search\n",
    "\n",
    "## Ingesting Our Dataset\n",
    "\n",
    "We'll use the `ivanleomk/ecommerce-taxonomy` dataset that we previously uploaded to Hugging Face. We want to use the same dataset so that the results are consistent.\n",
    "\n",
    "Our dataset contains the following fields\n",
    "\n",
    "- `image` : This is an image of the item\n",
    "- `brand` : The brand of the item\n",
    "- `title` : The title of the item\n",
    "- `description` : A description of the item\n",
    "- `category` : The category of the item\n",
    "- `subcategory` : The subcategory of the item\n",
    "- `product_type` : The product type of the item\n",
    "- `attributes` : A comma separated list of attributes of the item\n",
    "\n",
    "Let's now see how we can load these questions into our dataset and how retrieval doesn't work well when we only use semantic search with no metadata filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanleo/Documents/coding/systematically-improving-rag/cohort_2/week5/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=768x1024>,\n",
       " 'title': 'Lace Detail Sleeveless Top',\n",
       " 'brand': 'H&M',\n",
       " 'description': \"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace detailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day comfort.\",\n",
       " 'category': 'Women',\n",
       " 'subcategory': 'Tops',\n",
       " 'product_type': 'Tank Tops',\n",
       " 'attributes': '[{\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"}, {\"name\": \"Neckline\", \"value\": \"Crew Neck\"}]',\n",
       " 'material': 'Cotton',\n",
       " 'pattern': 'Solid',\n",
       " 'id': 1,\n",
       " 'price': 181.04}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ivanleomk/ecommerce-taxonomy\")[\"train\"]\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lancedb.pydantic import LanceModel, Vector\n",
    "import lancedb\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "\n",
    "# Create Embedding Function\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "# Define a Model that will be used as the schema for our collection\n",
    "class Item(LanceModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    description: str = func.SourceField()\n",
    "    brand: str\n",
    "    category: str\n",
    "    subcategory: str\n",
    "    product_type: str\n",
    "    attributes: str\n",
    "    material: str\n",
    "    pattern: str\n",
    "    price: float\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "table_name = \"items\"\n",
    "\n",
    "if table_name not in db.table_names():\n",
    "    table = db.create_table(table_name, schema=Item, mode=\"overwrite\")\n",
    "    entries = []\n",
    "    for row in ds:\n",
    "        entries.append(\n",
    "            {\n",
    "                \"id\": row[\"id\"],\n",
    "                \"title\": row[\"title\"],\n",
    "                \"description\": row[\"description\"],\n",
    "                \"brand\": row[\"brand\"],\n",
    "                \"category\": row[\"category\"],\n",
    "                \"subcategory\": row[\"subcategory\"],\n",
    "                \"product_type\": row[\"product_type\"],\n",
    "                \"attributes\": row[\"attributes\"],\n",
    "                \"material\": row[\"material\"],\n",
    "                \"pattern\": row[\"pattern\"],\n",
    "                \"price\": row[\"price\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    table.add(entries)\n",
    "\n",
    "table = db.open_table(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what we get back when we search for items and specify specific filters using semantic search.\n",
    "\n",
    "In this case, we're using a user query of `I need a polyester sweatshirt under $100?`. This requires the following filters to be applied - material, product type and price.\n",
    "\n",
    "We can see that when the relevant items are retrieved, they are not relevant to the user's query.\n",
    "\n",
    "- We're getting back items that are made of cotton instead of polyester\n",
    "- We're getting back items that are not sweatshirts\n",
    "- We're getting back items that are over $100 - some are even bottoms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"I need a polyester sweatshirt under a 100 bucks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>material</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike Air Sweatshirt</td>\n",
       "      <td>Stay comfortable and stylish with the Nike Air...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>96.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women's Ribbed Long Sleeve Sweater</td>\n",
       "      <td>This elegant ribbed sweater offers a snug fit,...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>237.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sleeveless Button-Down Blouse</td>\n",
       "      <td>This classic sleeveless button-down blouse is ...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>353.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embellished Graphic T-Shirt</td>\n",
       "      <td>This stylish oversized T-shirt from Replay fea...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>176.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White Crew Neck T-Shirt</td>\n",
       "      <td>This classic white crew neck t-shirt offers a ...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>229.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Classic Women's Crew Neck T-Shirt</td>\n",
       "      <td>This timeless crew neck t-shirt offers a relax...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>14.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Long Sleeve Crew Neck T-Shirt</td>\n",
       "      <td>This classic long sleeve crew neck t-shirt com...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>364.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Striped Long Sleeve Top</td>\n",
       "      <td>This classic striped long sleeve top features ...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>81.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Silk T-Shirt</td>\n",
       "      <td>This luxurious silk T-shirt features a soft, l...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Silk</td>\n",
       "      <td>99.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Striped Short Sleeve T-Shirt</td>\n",
       "      <td>This classic striped short-sleeve t-shirt is p...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>266.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                 Nike Air Sweatshirt   \n",
       "1  Women's Ribbed Long Sleeve Sweater   \n",
       "2       Sleeveless Button-Down Blouse   \n",
       "3         Embellished Graphic T-Shirt   \n",
       "4             White Crew Neck T-Shirt   \n",
       "5   Classic Women's Crew Neck T-Shirt   \n",
       "6       Long Sleeve Crew Neck T-Shirt   \n",
       "7             Striped Long Sleeve Top   \n",
       "8                        Silk T-Shirt   \n",
       "9        Striped Short Sleeve T-Shirt   \n",
       "\n",
       "                                         description category subcategory  \\\n",
       "0  Stay comfortable and stylish with the Nike Air...    Women        Tops   \n",
       "1  This elegant ribbed sweater offers a snug fit,...    Women        Tops   \n",
       "2  This classic sleeveless button-down blouse is ...    Women        Tops   \n",
       "3  This stylish oversized T-shirt from Replay fea...    Women        Tops   \n",
       "4  This classic white crew neck t-shirt offers a ...    Women        Tops   \n",
       "5  This timeless crew neck t-shirt offers a relax...    Women        Tops   \n",
       "6  This classic long sleeve crew neck t-shirt com...    Women        Tops   \n",
       "7  This classic striped long sleeve top features ...    Women        Tops   \n",
       "8  This luxurious silk T-shirt features a soft, l...    Women        Tops   \n",
       "9  This classic striped short-sleeve t-shirt is p...    Women        Tops   \n",
       "\n",
       "    material   price  \n",
       "0  Polyester   96.37  \n",
       "1     Cotton  237.07  \n",
       "2     Cotton  353.57  \n",
       "3     Cotton  176.58  \n",
       "4     Cotton  229.90  \n",
       "5     Cotton   14.60  \n",
       "6     Cotton  364.70  \n",
       "7     Cotton   81.09  \n",
       "8       Silk   99.63  \n",
       "9     Cotton  266.22  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "items = [\n",
    "    {\n",
    "        \"title\": item[\"title\"],\n",
    "        \"description\": item[\"description\"],\n",
    "        \"category\": item[\"category\"],\n",
    "        \"subcategory\": item[\"subcategory\"],\n",
    "        \"material\": item[\"material\"],\n",
    "        \"price\": item[\"price\"],\n",
    "    }\n",
    "    for item in table.search(query=user_query).limit(10).to_list()\n",
    "]\n",
    "\n",
    "pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see what happens when we apply the following filters on the material of the item and the product type of the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "table = db.open_table(\"items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>material</th>\n",
       "      <th>product_type</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike Air Sweatshirt</td>\n",
       "      <td>Stay comfortable and stylish with the Nike Air...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>Sweatshirts</td>\n",
       "      <td>96.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title                                        description  \\\n",
       "0  Nike Air Sweatshirt  Stay comfortable and stylish with the Nike Air...   \n",
       "\n",
       "  category subcategory   material product_type  price  \n",
       "0    Women        Tops  Polyester  Sweatshirts  96.37  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "items = [\n",
    "    {\n",
    "        \"title\": item[\"title\"],\n",
    "        \"description\": item[\"description\"],\n",
    "        \"category\": item[\"category\"],\n",
    "        \"subcategory\": item[\"subcategory\"],\n",
    "        \"material\": item[\"material\"],\n",
    "        \"product_type\": item[\"product_type\"],\n",
    "        \"price\": item[\"price\"],\n",
    "    }\n",
    "    for item in table.search(query=user_query)\n",
    "    .limit(10)\n",
    "    # Apply a prefilter to only get polyester sweatshirts\n",
    "    .where(\"material='Polyester' AND product_type='Sweatshirts' AND price < 100\", prefilter=True)\n",
    "    .to_list()\n",
    "]\n",
    "\n",
    "pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these 3 new filters that we're applying on the results, we're now getting back items that fit the user's specific requirements - which were polyester sweatshirts under $100. As our dataset grows and we support more items, we'll then progressively add in more filters such as the brand or occasion etc.\n",
    "\n",
    "As queries become more complex, metadata filtering will only become more important. Now let's see how we can use LLMs to automatically label and extract data to support a new category of filters that we'd like to support. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Metadata Generation\n",
    "\n",
    "> If you'd like to skip the labelling process, you can download the labelled dataset from huggingface at `ivanleomk/labelled-ecommerce-taxonomy` which you can find [here](https://huggingface.co/datasets/ivanleomk/labelled-ecommerce-taxonomy)\n",
    "\n",
    "We've seen how semantic search falls short when we have complex queries that require not results to be relevant but valid. \n",
    "\n",
    "In the example above, valid items are those that meet the user's requirements and have the following characteristics\n",
    "\n",
    "- Material: Polyester\n",
    "- Product Type: Sweatshirts\n",
    "- Price: Under $100\n",
    "\n",
    "Imagine that we now want to allow users to search for items based on an occasion - say a wedding or interview that they need to attend. We don't have this information in our current dataset and getting a human to label this would be a tedious process.\n",
    "\n",
    "Therefore, we can leverage LLMs to automatically label and extract this information for us. To make things easier, we've already defined a `occasions` field in our `taxonomy.yml` file.\n",
    "\n",
    "We'll label our entire dataset in three steps\n",
    "\n",
    "1. First we'll read in the taxonomy file to get a list of valid occasions. By reading from a config file, we can prevent potential errors such as typos and ensure that the occasions are valid when we generate them and use them to perform filtering. \n",
    "\n",
    "2. Next, we'll use a language model and batch requests to label each item in our dataset with the appropriate occasions using its metadata and its image.\n",
    "\n",
    "3. Finally, we'll save this as a new column in our dataset and upload it to Hugging Face to save.\n",
    "\n",
    "Once we've done so, we'll then work towards implementing an occasion filter in our retrieval pipeline and see how it compares to semantic search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Labels\n",
    "\n",
    "We can see here that we've got a list of occasions here that items can be worn for. Note that since it's completely possible for an item to be worn for multiple occasions\n",
    "\n",
    "Eg. a black dress can be worn for both formal and casual occasions.\n",
    "\n",
    "Therefore, what we'll do is to allow the model to output a list of occasions that the item can be worn for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import process_taxonomy_file\n",
    "\n",
    "# Read in taxonomy data\n",
    "taxonomy_data = process_taxonomy_file(\"./taxonomy.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'image'</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">PIL.JpegImagePlugin.JpegImageFile</span><span style=\"color: #000000; text-decoration-color: #000000\"> image </span><span style=\"color: #808000; text-decoration-color: #808000\">mode</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080\">RGB</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #808000; text-decoration-color: #808000\">size</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080\">768x1024</span><span style=\"color: #000000; text-decoration-color: #000000\"> at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x12ACDC080</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Lace Detail Sleeveless Top'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'brand'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'H&amp;M'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">detailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comfort.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'category'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Women'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'subcategory'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tops'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'product_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tank Tops'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[{\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"}, {\"name\": \"Neckline\", \"value\": \"Crew Neck\"}]'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'material'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Cotton'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pattern'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solid'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">181.04</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'occasions'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Casual Outings'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Smart Casual'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Partywear'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Dinner Dates'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Everyday Wear'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'image'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mPIL.JpegImagePlugin.JpegImageFile\u001b[0m\u001b[39m image \u001b[0m\u001b[33mmode\u001b[0m\u001b[39m=\u001b[0m\u001b[35mRGB\u001b[0m\u001b[39m \u001b[0m\u001b[33msize\u001b[0m\u001b[39m=\u001b[0m\u001b[35m768x1024\u001b[0m\u001b[39m at \u001b[0m\u001b[1;36m0x12ACDC080\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m: \u001b[32m'Lace Detail Sleeveless Top'\u001b[0m,\n",
       "    \u001b[32m'brand'\u001b[0m: \u001b[32m'H&M'\u001b[0m,\n",
       "    \u001b[32m'description'\u001b[0m: \u001b[32m\"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace \u001b[0m\n",
       "\u001b[32mdetailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day \u001b[0m\n",
       "\u001b[32mcomfort.\"\u001b[0m,\n",
       "    \u001b[32m'category'\u001b[0m: \u001b[32m'Women'\u001b[0m,\n",
       "    \u001b[32m'subcategory'\u001b[0m: \u001b[32m'Tops'\u001b[0m,\n",
       "    \u001b[32m'product_type'\u001b[0m: \u001b[32m'Tank Tops'\u001b[0m,\n",
       "    \u001b[32m'attributes'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\": \"Neckline\", \"value\": \"Crew Neck\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[32m'material'\u001b[0m: \u001b[32m'Cotton'\u001b[0m,\n",
       "    \u001b[32m'pattern'\u001b[0m: \u001b[32m'Solid'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'price'\u001b[0m: \u001b[1;36m181.04\u001b[0m,\n",
       "    \u001b[32m'occasions'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Casual Outings'\u001b[0m, \u001b[32m'Smart Casual'\u001b[0m, \u001b[32m'Partywear'\u001b[0m, \u001b[32m'Dinner Dates'\u001b[0m, \u001b[32m'Everyday Wear'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic import BaseModel, field_validator, ValidationInfo\n",
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "from asyncio import Semaphore, timeout\n",
    "from tqdm.asyncio import tqdm_asyncio as asyncio\n",
    "import tempfile\n",
    "from rich import print\n",
    "\n",
    "\n",
    "# Define a Pydantic model to validate the occasions\n",
    "class Occasions(BaseModel):\n",
    "    occasions: list[str]\n",
    "\n",
    "    @field_validator(\"occasions\")\n",
    "    def validate_occasions(cls, v, info: ValidationInfo):\n",
    "        if not v:\n",
    "            raise ValueError(\"Occasions cannot be empty\")\n",
    "\n",
    "        context = info.context\n",
    "        occasions = context[\"taxonomy_data\"][\"occasions\"]\n",
    "\n",
    "        # Since the model can output a list of occasions, we need to check that each occasion is valid\n",
    "        for occasion in v:\n",
    "            if occasion not in occasions:\n",
    "                raise ValueError(f\"Invalid occasion: {occasion}\")\n",
    "        return v\n",
    "\n",
    "\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "\n",
    "async def generate_occasions(\n",
    "    item: dict,\n",
    "    client: instructor.AsyncInstructor,\n",
    "    semaphore: Semaphore,\n",
    "    taxonomy_data: dict,\n",
    "):\n",
    "    async with semaphore, timeout(30):\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".jpg\") as temp_file:\n",
    "            # Save the PIL image to the temporary file\n",
    "            item[\"image\"].save(temp_file.name)\n",
    "\n",
    "            occasions = await client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            \"\"\"\n",
    "                            You're an expert AI system that excels at identifying potential occasions that an item can be worn for.\n",
    "\n",
    "                            Here is a list of valid occasions that we'd like you to consider:\n",
    "                            : {{ taxonomy_data['occasions'] }}\n",
    "                            \n",
    "                            Consider the following details about the item:\n",
    "                            \n",
    "                            Title: {{ title }}\n",
    "                            Description: {{ description }}\n",
    "                            Brand: {{ brand }}\n",
    "                            Material: {{ material }}\n",
    "                            Pattern: {{ pattern }}\n",
    "                            Attributes: {{ attributes }}\n",
    "                            \n",
    "                            Please analyze these details along with the image to determine appropriate occasions that this specific item in the image can be worn for.\n",
    "                        \"\"\",\n",
    "                            instructor.Image.from_path(temp_file.name),\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "                response_model=Occasions,\n",
    "                context={\n",
    "                    \"taxonomy_data\": taxonomy_data,\n",
    "                    \"title\": item[\"title\"],\n",
    "                    \"description\": item[\"description\"],\n",
    "                    \"brand\": item[\"brand\"],\n",
    "                    \"material\": item[\"material\"],\n",
    "                    \"pattern\": item[\"pattern\"],\n",
    "                    \"attributes\": item[\"attributes\"],\n",
    "                },\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                **item,\n",
    "                \"occasions\": occasions.occasions,\n",
    "            }\n",
    "\n",
    "\n",
    "sem = Semaphore(10)\n",
    "print(await generate_occasions(ds[0], client, sem, taxonomy_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we've now got a list of occasions that the item can be worn for so let's apply this to our dataset.\n",
    "\n",
    "We'll label all of our items in the dataset, save it to hugging face and then ingest it into a new LanceDB database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [01:05<00:00,  2.91it/s]\n",
      "Map: 100%|██████████| 191/191 [00:00<00:00, 16796.21 examples/s]/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 303.21ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ivanleomk/labelled-ecommerce-taxonomy/commit/c098a983271ba27ece46fe780ac004093eccffa6', commit_message='Upload dataset', commit_description='', oid='c098a983271ba27ece46fe780ac004093eccffa6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ivanleomk/labelled-ecommerce-taxonomy', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ivanleomk/labelled-ecommerce-taxonomy'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "coros = [\n",
    "    generate_occasions(item, client, sem, taxonomy_data)\n",
    "    for item in ds\n",
    "    if item[\"category\"]\n",
    "]\n",
    "occasions = await asyncio.gather(*coros)\n",
    "\n",
    "labelled_dataset = Dataset.from_list(\n",
    "    [\n",
    "        {\n",
    "            **item,\n",
    "            \"occasions\": json.dumps(item[\"occasions\"]),\n",
    "        }\n",
    "        for item in occasions\n",
    "    ]\n",
    ")\n",
    "labelled_dataset.push_to_hub(\"ivanleomk/labelled-ecommerce-taxonomy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reingesting our data\n",
    "\n",
    "Now that we've labelled our dataset, let's load it back in and ingest it into a new LanceDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 191/191 [00:00<00:00, 16135.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "labelled_dataset = load_dataset(\"ivanleomk/labelled-ecommerce-taxonomy\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lancedb.pydantic import LanceModel, Vector\n",
    "import lancedb\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "\n",
    "# Create Embedding Function\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "# Define a Model that will be used as the schema for our collection\n",
    "class Item(LanceModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    description: str = func.SourceField()\n",
    "    brand: str\n",
    "    category: str\n",
    "    subcategory: str\n",
    "    product_type: str\n",
    "    attributes: str\n",
    "    occasions: str\n",
    "    material: str\n",
    "    pattern: str\n",
    "    price: float\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "table_name = \"labelled_items\"\n",
    "\n",
    "if table_name not in db.table_names():\n",
    "    labelled_table = db.create_table(table_name, schema=Item, mode=\"overwrite\")\n",
    "    entries = []\n",
    "    for row in labelled_dataset:\n",
    "        entries.append(\n",
    "            {\n",
    "                \"id\": row[\"id\"],\n",
    "                \"title\": row[\"title\"],\n",
    "                \"description\": row[\"description\"],\n",
    "                \"brand\": row[\"brand\"],\n",
    "                \"category\": row[\"category\"],\n",
    "                \"subcategory\": row[\"subcategory\"],\n",
    "                \"product_type\": row[\"product_type\"],\n",
    "                \"attributes\": row[\"attributes\"],\n",
    "                \"occasions\": row[\"occasions\"],\n",
    "                \"material\": row[\"material\"],\n",
    "                \"pattern\": row[\"pattern\"],\n",
    "                \"price\": row[\"price\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    labelled_table.add(entries)\n",
    "\n",
    "labelled_table = db.open_table(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that we've inserted the right number of rows into the dataset\n",
    "labelled_table.count_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Understanding\n",
    "\n",
    "Now that we've generated these new occasion labels as metadata using a language model, let's see how we can use this to improve our retrieval evals.\n",
    "\n",
    "We'll do so in three steps\n",
    "\n",
    "1. **Generate Synthetic Queries** : We'll generate queries that require metadata filtering and measure the recall and mrr of semantic search\n",
    "\n",
    "2. **Extract Query Filters** : Once we've generated these queries and calculated an initial baseline, we'll then implement a function that takes a user's query and maps it to a list of predefined filters.\n",
    "\n",
    "3. **Evaluate** : We'll then evaluate the performance of our retrieval pipeline with metadata filtering against our initial baseline using metrics such as recall and mrr.\n",
    "\n",
    "Once we've done so, we'll see how metadata filtering helps improve the recall and mrr of retrieval pipelines on average by removing irrelevant items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Queries\n",
    "\n",
    "When users come to our application, more often than not, they'll come with specific requirements in mind.\n",
    "\n",
    "Even if they're just looking for a casual t-shirt, they'll have preferences such as \n",
    "\n",
    "- material\n",
    "- price\n",
    "- specific categories/occasions that they're looking to wear these items for\n",
    "\n",
    "We can simulate these by generating queries that contain these requirements as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = [item for item in load_dataset(\"ivanleomk/labelled-ecommerce-taxonomy\")[\"train\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Looking for a chic sleeveless tank with lace details for casual dinners. Must be comfy and stylish </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">under $200. Prefer something breathable in cotton.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'image'</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">PIL.JpegImagePlugin.JpegImageFile</span><span style=\"color: #000000; text-decoration-color: #000000\"> image </span><span style=\"color: #808000; text-decoration-color: #808000\">mode</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080\">RGB</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #808000; text-decoration-color: #808000\">size</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080\">768x1024</span><span style=\"color: #000000; text-decoration-color: #000000\"> at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x12CBCEC00</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Lace Detail Sleeveless Top'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'brand'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'H&amp;M'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">detailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comfort.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'category'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Women'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'subcategory'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tops'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'product_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tank Tops'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[{\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"}, {\"name\": \"Neckline\", \"value\": \"Crew Neck\"}]'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'material'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Cotton'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pattern'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solid'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">181.04</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'occasions'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[\"Everyday Wear\", \"Casual Outings\", \"Smart Casual\", \"Dinner Dates\", \"Partywear\"]'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'query'\u001b[0m: \u001b[32m'Looking for a chic sleeveless tank with lace details for casual dinners. Must be comfy and stylish \u001b[0m\n",
       "\u001b[32munder $200. Prefer something breathable in cotton.'\u001b[0m,\n",
       "    \u001b[32m'image'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mPIL.JpegImagePlugin.JpegImageFile\u001b[0m\u001b[39m image \u001b[0m\u001b[33mmode\u001b[0m\u001b[39m=\u001b[0m\u001b[35mRGB\u001b[0m\u001b[39m \u001b[0m\u001b[33msize\u001b[0m\u001b[39m=\u001b[0m\u001b[35m768x1024\u001b[0m\u001b[39m at \u001b[0m\u001b[1;36m0x12CBCEC00\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m: \u001b[32m'Lace Detail Sleeveless Top'\u001b[0m,\n",
       "    \u001b[32m'brand'\u001b[0m: \u001b[32m'H&M'\u001b[0m,\n",
       "    \u001b[32m'description'\u001b[0m: \u001b[32m\"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace \u001b[0m\n",
       "\u001b[32mdetailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day \u001b[0m\n",
       "\u001b[32mcomfort.\"\u001b[0m,\n",
       "    \u001b[32m'category'\u001b[0m: \u001b[32m'Women'\u001b[0m,\n",
       "    \u001b[32m'subcategory'\u001b[0m: \u001b[32m'Tops'\u001b[0m,\n",
       "    \u001b[32m'product_type'\u001b[0m: \u001b[32m'Tank Tops'\u001b[0m,\n",
       "    \u001b[32m'attributes'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\": \"Neckline\", \"value\": \"Crew Neck\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[32m'material'\u001b[0m: \u001b[32m'Cotton'\u001b[0m,\n",
       "    \u001b[32m'pattern'\u001b[0m: \u001b[32m'Solid'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'price'\u001b[0m: \u001b[1;36m181.04\u001b[0m,\n",
       "    \u001b[32m'occasions'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Everyday Wear\", \"Casual Outings\", \"Smart Casual\", \"Dinner Dates\", \"Partywear\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tempfile\n",
    "from asyncio import Semaphore, timeout\n",
    "from pydantic import BaseModel\n",
    "from openai import AsyncOpenAI\n",
    "import instructor\n",
    "import random\n",
    "from rich import print\n",
    "\n",
    "# Define possible user intents\n",
    "user_intent = [\n",
    "    \"searching for clothing that matches their style and needs\",\n",
    "    \"shopping for a specific occasion\",\n",
    "    \"looking for a particular type of clothing\",\n",
    "]\n",
    "\n",
    "# Define potential filters that can be used in queries\n",
    "potential_filters = [\n",
    "    \"material\",\n",
    "    \"price\",\n",
    "    \"category\",\n",
    "    \"subcategory\",\n",
    "    \"product_type\",\n",
    "    \"occasions\",\n",
    "    \"material\",\n",
    "    \"pattern\",\n",
    "    \"attributes\",\n",
    "]\n",
    "\n",
    "\n",
    "class UserQuery(BaseModel):\n",
    "    chain_of_thought: str\n",
    "    query: str\n",
    "\n",
    "\n",
    "async def generate_query(\n",
    "    client, item, user_intent, potential_filters, semaphore: Semaphore\n",
    "):\n",
    "    async with semaphore, timeout(30):\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete_on_close=True) as tmp:\n",
    "            # Save the image to the temp file\n",
    "            item[\"image\"].save(tmp.name)\n",
    "\n",
    "            # Create the chat completion\n",
    "            response = await client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                response_model=UserQuery,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"\"\"You are helping generate realistic shopping queries where the provided item would be the perfect answer.\n",
    "                        The generated query should naturally lead to recommending this specific item.\"\"\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            \"\"\"\n",
    "Generate a natural shopping query where this item would be the perfect recommendation.\n",
    "The query should match someone who is {{user_intent}}.\n",
    "\n",
    "Item Details:\n",
    "- Title: {{title}}\n",
    "- Description: {{description}}\n",
    "- Brand: {{brand}}\n",
    "- Material: {{material}}\n",
    "- Pattern: {{pattern}}\n",
    "- Attributes: {{attributes}}\n",
    "- Occasions: {{occasions}}\n",
    "- Price: {{price}}\n",
    "- Category: {{category}}\n",
    "- Subcategory: {{subcategory}}\n",
    "- Product Type: {{product_type}}\n",
    "\n",
    "Consider these aspects when generating the query: {{potential_filters}}\n",
    "\n",
    "Requirements:\n",
    "- Query should be 20-30 words\n",
    "- Conversational tone\n",
    "- The query should describe the aspects above that make the item above a perfect match for the user's requirements\n",
    "- Try to mention things which might be synonyms for the item and avoid mentioning it directly. Instead we should use specific attributes that the item has in order to make it a good fit. Make sure to use the exact attribute name so that it's unambigious\n",
    "- for the price range, keep it to 15 bucks on either side of the price max\n",
    "- If there is a slight mismatch between the item's title and the subcategory/product type, lean towards the subcategory/product type. (Eg. Title is a \"Black Women's Top\" but the subcategory is \"Sweater\", then make the query about a \"Black Sweater\")\n",
    "\n",
    "For an office blouse that costs $120:\n",
    "\"Need something elegant for my new corporate job. Looking for a silk top with long sleeves and a modest neckline, under $150.\" ( Within the price range here )\n",
    "\n",
    "For casual wear that costs $65:\n",
    "\"Shopping for my weekend brunches. Need a cotton top that's both comfy and stylish, maybe with some interesting pattern - ideally something between 40-100 bucks if possible.\" ( 65 is less than 69 )\n",
    "\n",
    "Remember: The query should describe what someone would be looking for if this exact item would be their perfect match!\n",
    "                            \"\"\",\n",
    "                            instructor.Image.from_path(tmp.name),\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "                context={\n",
    "                    \"user_intent\": user_intent,\n",
    "                    \"potential_filters\": potential_filters,\n",
    "                    \"title\": item[\"title\"],\n",
    "                    \"description\": item[\"description\"],\n",
    "                    \"brand\": item[\"brand\"],\n",
    "                    \"material\": item[\"material\"],\n",
    "                    \"pattern\": item[\"pattern\"],\n",
    "                    \"attributes\": item[\"attributes\"],\n",
    "                    \"price\": item[\"price\"],\n",
    "                    \"category\": item[\"category\"],\n",
    "                    \"subcategory\": item[\"subcategory\"],\n",
    "                    \"product_type\": item[\"product_type\"],\n",
    "                    \"occasions\": item[\"occasions\"],\n",
    "                },\n",
    "            )\n",
    "            return {\n",
    "                \"query\": response.query,\n",
    "                **item,\n",
    "            }\n",
    "\n",
    "\n",
    "sem = Semaphore(10)\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "user_intent = random.choice(user_intent)\n",
    "filters = random.sample(potential_filters, random.randint(2, len(potential_filters)))\n",
    "print(await generate_query(client, ds[0], user_intent, filters, sem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:13<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.asyncio import tqdm_asyncio as asyncio\n",
    "\n",
    "\n",
    "coros = [generate_query(client, item, user_intent, filters, sem) for item in ds[50:70]]\n",
    "\n",
    "queries = await asyncio.gather(*coros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"queries.json\", \"a\") as f:\n",
    "    for query in queries:\n",
    "        # Cannot save image to JSON so we remove it\n",
    "        query_without_image = {k: v for k, v in query.items() if k != \"image\"}\n",
    "        f.write(json.dumps(query_without_image) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Initial Baseline\n",
    "\n",
    "Now that we've generated an initial set of queries, let's see how semantic search performs on them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load in queries that we generated previously\n",
    "with open(\"queries.json\", \"r\") as f:\n",
    "    queries = [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-5-1733325918 is running at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733325918\n",
      "query-generation (data): 38it [00:00, 52035.11it/s]\n",
      "query-generation (tasks): 100%|██████████| 38/38 [00:01<00:00, 27.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-5-1733325918 compared to week-5-1733325860:\n",
      "39.47% 'mrr@1'     score\n",
      "45.61% 'mrr@3'     score\n",
      "47.19% 'mrr@5'     score\n",
      "48.98% 'mrr@10'    score\n",
      "49.16% 'mrr@15'    score\n",
      "49.47% 'mrr@25'    score\n",
      "39.47% 'recall@1'  score\n",
      "55.26% 'recall@3'  score\n",
      "63.16% 'recall@5'  score\n",
      "76.32% 'recall@10' score\n",
      "78.95% 'recall@15' score\n",
      "84.21% 'recall@25' score\n",
      "\n",
      "0.74s duration\n",
      "\n",
      "See results for week-5-1733325918 at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733325918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvalResultWithSummary(summary=\"...\", results=[...])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from braintrust import Eval, Score\n",
    "from helpers import get_metrics_at_k\n",
    "\n",
    "import lancedb\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "table = db.open_table(\"labelled_items\")\n",
    "\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    metrics = get_metrics_at_k(metrics=[\"mrr\", \"recall\"], sizes=[1, 3, 5, 10, 15, 25])\n",
    "    return [\n",
    "        Score(\n",
    "            name=metric,\n",
    "            score=score_fn(output, kwargs[\"expected\"]),\n",
    "            metadata={\"query\": input, \"result\": output, **kwargs[\"metadata\"]},\n",
    "        )\n",
    "        for metric, score_fn in metrics.items()\n",
    "    ]\n",
    "\n",
    "\n",
    "def retrieve_items(query: str, table, hooks):\n",
    "    # Search using the query text\n",
    "    results = table.search(query).limit(25).to_list()\n",
    "\n",
    "    hooks.meta(\n",
    "        query=query,\n",
    "        items=[\n",
    "            {**{k: v for k, v in item.items() if k not in [\"vector\", \"image\"]}}\n",
    "            for item in results\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return [item[\"id\"] for item in results]\n",
    "\n",
    "\n",
    "await Eval(\n",
    "    \"query-generation\",\n",
    "    data=lambda: [\n",
    "        {\"input\": query[\"query\"], \"expected\": [query[\"id\"]]} for query in queries\n",
    "    ],\n",
    "    task=lambda query, hooks: retrieve_items(query, table, hooks),\n",
    "    scores=[evaluate_braintrust],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Query Filters\n",
    "\n",
    "We can see that semantic search performs decently on our initial set of queries, at k=15, we have recall@15 of ~0.79 and mrr@15 of ~0.75.\n",
    "\n",
    "But if we look at the returned items itself, you'll notice that some should not have been returned in the queries.\n",
    "\n",
    "Eg. Query : \"Looking for a chic blouse for dinner dates and evening events. Needs to be long sleeve with floral pattern and crew neck, ideally under $50.\"\n",
    "\n",
    "- First item returned has a price of 89 which is above the user's budget\n",
    "- Within the 25 returned items, we had a few items that were of different subcategories such as Tank Tops.\n",
    "\n",
    "In many other examples, you might see this as items being returned from the wrong category, having a price that doesn't match the user's budget or simply put items that don't match the user's requirements.\n",
    "\n",
    "Query Understanding is one way that we can address this. \n",
    "\n",
    "We use `instructor` here because we can use Pydantic to validate the extracted filters.That gives us an easy way to validate if the filter values are valid. \n",
    "\n",
    "We want to use a ValidationInfo instead of hard-coding it into the code because that allows us to potentially reuse this for other datasets with different taxonomies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, model_validator\n",
    "\n",
    "\n",
    "class Attribute(BaseModel):\n",
    "    name: str\n",
    "    values: list[str]\n",
    "\n",
    "\n",
    "class QueryFilters(BaseModel):\n",
    "    attributes: list[Attribute]\n",
    "    material: Optional[list[str]]\n",
    "    min_price: Optional[float] = None\n",
    "    max_price: Optional[float] = None\n",
    "    subcategory: str\n",
    "    category: str\n",
    "    product_type: list[str]\n",
    "    occasions: list[str]\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_attributes(self):\n",
    "        # Validate category exists in taxonomy\n",
    "        if self.category not in taxonomy_data[\"taxonomy_map\"]:\n",
    "            raise ValueError(\n",
    "                f\"Invalid category: {self.category}. Valid categories are {taxonomy_data['taxonomy_map'].keys()}\"\n",
    "            )\n",
    "\n",
    "        # Validate subcategory exists under category\n",
    "        if self.subcategory not in taxonomy_data[\"taxonomy_map\"][self.category]:\n",
    "            raise ValueError(\n",
    "                f\"Invalid subcategory {self.subcategory} for category {self.category}. Valid subcategories are {taxonomy_data['taxonomy_map'][self.category]}\"\n",
    "            )\n",
    "\n",
    "        # Validate product types\n",
    "        valid_types = taxonomy_data[\"taxonomy_map\"][self.category][self.subcategory][\n",
    "            \"product_type\"\n",
    "        ]\n",
    "        for product_type in self.product_type:\n",
    "            if product_type not in valid_types:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid product type: {product_type}. Valid product types are {valid_types}\"\n",
    "                )\n",
    "\n",
    "        # Validate attributes\n",
    "        valid_attrs = taxonomy_data[\"taxonomy_map\"][self.category][self.subcategory][\n",
    "            \"attributes\"\n",
    "        ]\n",
    "        for attr in self.attributes:\n",
    "            if attr.name not in valid_attrs:\n",
    "                raise ValueError(f\"Invalid attribute name: {attr.name}\")\n",
    "            for value in attr.values:\n",
    "                if value not in valid_attrs[attr.name]:\n",
    "                    raise ValueError(\n",
    "                        f\"Invalid value {value} for attribute {attr.name}. Valid values are {valid_attrs[attr.name]}\"\n",
    "                    )\n",
    "\n",
    "        # Validate occasions\n",
    "        for occasion in self.occasions:\n",
    "            if occasion not in taxonomy_data[\"occasions\"]:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid occasion: {occasion}. Valid Occasions are {taxonomy_data['occasions']}\"\n",
    "                )\n",
    "\n",
    "        # Validate materials if provided\n",
    "        if self.material:\n",
    "            for material in self.material:\n",
    "                if material not in taxonomy_data[\"materials\"]:\n",
    "                    raise ValueError(\n",
    "                        f\"Invalid material: {material}. Valid Materials are {taxonomy_data['materials']}\"\n",
    "                    )\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finished defining our Pydantic model, let's see how we can use it to extract filters from a user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QueryFilters</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">attributes</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Attribute</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Sleeve Length'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">values</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Sleeveless'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Short Sleeve'</span><span style=\"font-weight: bold\">])]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">material</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">min_price</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">max_price</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">subcategory</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Tops'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">category</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Women'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">product_type</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tank Tops'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">occasions</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Office Wear'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mQueryFilters\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mattributes\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mAttribute\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'Sleeve Length'\u001b[0m, \u001b[33mvalues\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Sleeveless'\u001b[0m, \u001b[32m'Short Sleeve'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmaterial\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmin_price\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmax_price\u001b[0m=\u001b[1;36m100\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33msubcategory\u001b[0m=\u001b[32m'Tops'\u001b[0m,\n",
       "    \u001b[33mcategory\u001b[0m=\u001b[32m'Women'\u001b[0m,\n",
       "    \u001b[33mproduct_type\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Tank Tops'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33moccasions\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Office Wear'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import instructor\n",
    "from helpers import process_taxonomy_file\n",
    "from rich import print\n",
    "\n",
    "client = instructor.from_openai(OpenAI())\n",
    "taxonomy_data = process_taxonomy_file(\"taxonomy.yml\")\n",
    "query = \"I want a Tank-Top that's got a short sleeve or sleeveless which is under 100 bucks for an interview\"\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that extracts user requirements from a query. Refer to this taxonomy for valid categories, subcategories, product types and attributes: {{taxonomy}}. If a filter isn't needed, just return an empty list. Refer to the occasions list for valid occasions if the user is looking for an occasion specific item: {{occasions}}. Refer to the materials list for valid materials if the user is looking for a specific material: {{materials}} else just return an empty list. Attributes with the same name should just be grouped together. If the user is looking for a specific attribute, just return the attribute name and the values that the user is looking for\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ],\n",
    "    context={\n",
    "        \"taxonomy_map\": taxonomy_data[\"taxonomy_map\"],\n",
    "        \"taxonomy\": taxonomy_data[\"taxonomy\"],\n",
    "        \"occasions\": taxonomy_data[\"occasions\"],\n",
    "        \"materials\": taxonomy_data[\"materials\"],\n",
    "    },\n",
    "    response_model=QueryFilters,\n",
    ")\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import lancedb\n",
    "import pandas as pd\n",
    "import instructor\n",
    "\n",
    "\n",
    "async def extract_query_filters(\n",
    "    query: str, client: openai.AsyncOpenAI, taxonomy_data: dict\n",
    ") -> QueryFilters:\n",
    "    return await client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                    You are a helpful assistant that extracts user requirements from a query.\n",
    "                    \n",
    "                    Use these references:\n",
    "                    - Taxonomy: {{ taxonomy }}\n",
    "                    - Valid occasions: {{ occasions }} \n",
    "                    - Valid materials: {{ materials }}\n",
    "                    \n",
    "                    Guidelines:\n",
    "                    - If a filter isn't needed, return an empty list\n",
    "                    - Only add attributes and filters that a user has mentioned explicitly\n",
    "                    - Only use values from the provided taxonomy, occasions and materials lists. \n",
    "                    - If the attribute exists on multiple types, make sure that you only look at the specific types listed under the subcategory you have chosen\n",
    "                    - If the user hasn't mentioned a specific product type, lets just use all of them\n",
    "                    - if the user gives a range (Eg. around 50), just give a buffer of 20 on each side (Eg. 30-70)\n",
    "                    - if the user gives a vague price (Eg. I have a high budget), just set max price to 1000\n",
    "                    - only classify an item as unisex if the user has explicitly mentioned it and default to Women's categories by default.\n",
    "                    - If you're looking at blouses, make sure to include tank tops along the way and vice versa\n",
    "                    - if the user mentions user bottoms and doesn't specify a specific length - let's include both short and long bottoms such as jeans, shorts and pants\n",
    "                    - make sure to look carefully at the user's query to determine if they've specified a specific fit - eg. regular, relaxed, cropped. ( Relaxed and Relaxed should always go together)\n",
    "\n",
    "                    Extract the requirements and format them according to the QueryFilters model.\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        context={\n",
    "            \"taxonomy_map\": taxonomy_data[\"taxonomy_map\"],\n",
    "            \"taxonomy\": taxonomy_data[\"taxonomy\"],\n",
    "            \"occasions\": taxonomy_data[\"occasions\"],\n",
    "            \"materials\": taxonomy_data[\"materials\"],\n",
    "        },\n",
    "        response_model=QueryFilters,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define some tests to make sure the filters can be extracted as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QueryFilters</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">attributes</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">material</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Polyester'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">min_price</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">max_price</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">subcategory</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Tops'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">category</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Women'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">product_type</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Sweatshirts'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">occasions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mQueryFilters\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mattributes\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmaterial\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Polyester'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmin_price\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmax_price\u001b[0m=\u001b[1;36m100\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33msubcategory\u001b[0m=\u001b[32m'Tops'\u001b[0m,\n",
       "    \u001b[33mcategory\u001b[0m=\u001b[32m'Women'\u001b[0m,\n",
       "    \u001b[33mproduct_type\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Sweatshirts'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33moccasions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import instructor\n",
    "import openai\n",
    "\n",
    "client = instructor.from_openai(openai.AsyncOpenAI())\n",
    "taxonomy_data = process_taxonomy_file(\"taxonomy.yml\")\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "table = db.open_table(\"labelled_items\")\n",
    "\n",
    "test_query = \"I need a polyester sweatshirt under a 100 bucks\"\n",
    "generated_filter = await extract_query_filters(test_query, client, taxonomy_data)\n",
    "print(generated_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since lancedb doesn't support prefiltering by list[str], we need to manually filter the items based on the product_type, material and occasions. \n",
    "\n",
    "This is known as a post-filtering step. We want to do so  because this is the easiest way to handle the filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>product_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>occasions</th>\n",
       "      <th>material</th>\n",
       "      <th>pattern</th>\n",
       "      <th>price</th>\n",
       "      <th>vector</th>\n",
       "      <th>_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>Nike Air Sweatshirt</td>\n",
       "      <td>Stay comfortable and stylish with the Nike Air...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Sweatshirts</td>\n",
       "      <td>[{'name': 'Sleeve Length', 'value': 'Long Slee...</td>\n",
       "      <td>[Everyday Wear, Casual Outings, Activewear, Sp...</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>Solid</td>\n",
       "      <td>96.37</td>\n",
       "      <td>[0.03836069256067276, 0.024997683241963387, -0...</td>\n",
       "      <td>1.21256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                title                                        description  \\\n",
       "0  53  Nike Air Sweatshirt  Stay comfortable and stylish with the Nike Air...   \n",
       "\n",
       "  brand category subcategory product_type  \\\n",
       "0  Nike    Women        Tops  Sweatshirts   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  [{'name': 'Sleeve Length', 'value': 'Long Slee...   \n",
       "\n",
       "                                           occasions   material pattern  \\\n",
       "0  [Everyday Wear, Casual Outings, Activewear, Sp...  Polyester   Solid   \n",
       "\n",
       "   price                                             vector  _distance  \n",
       "0  96.37  [0.03836069256067276, 0.024997683241963387, -0...    1.21256  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def retrieve_and_filter(query: str, table, filters: QueryFilters, max_k=100):\n",
    "    query_parts = []\n",
    "\n",
    "    # We do a prefilter on category,price and material since these will always be provided\n",
    "    query_parts.append(f\"category='{filters.category}'\")\n",
    "    query_parts.append(f\"subcategory='{filters.subcategory}'\")\n",
    "\n",
    "    if filters.min_price:\n",
    "        query_parts.append(f\"price >= {filters.min_price}\")\n",
    "    if filters.max_price:\n",
    "        query_parts.append(f\"price <= {filters.max_price}\")\n",
    "\n",
    "    query_string = \" AND \".join(query_parts)\n",
    "    items = (\n",
    "        table.search(query=query)\n",
    "        .where(query_string, prefilter=True)\n",
    "        .limit(max_k)\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "    items = [\n",
    "        {\n",
    "            **item,\n",
    "            \"attributes\": json.loads(item[\"attributes\"]),\n",
    "            \"occasions\": json.loads(item[\"occasions\"]),\n",
    "        }\n",
    "        for item in items\n",
    "    ]\n",
    "\n",
    "    if filters.product_type:\n",
    "        items = [item for item in items if item[\"product_type\"] in filters.product_type]\n",
    "\n",
    "    if filters.material:\n",
    "        items = [item for item in items if item[\"material\"] in filters.material]\n",
    "\n",
    "    if filters.occasions:\n",
    "        items = [\n",
    "            item\n",
    "            for item in items\n",
    "            if any(occasion in item[\"occasions\"] for occasion in filters.occasions)\n",
    "        ]\n",
    "\n",
    "    if filters.attributes:\n",
    "        for attr in filters.attributes:\n",
    "            if not attr.values:\n",
    "                continue\n",
    "            curr_items = []\n",
    "            for item in items:\n",
    "                attr_name = attr.name\n",
    "                attr_values = attr.values\n",
    "                item_attr_values = item[\"attributes\"]\n",
    "                for item_attr in item_attr_values:\n",
    "                    if (\n",
    "                        item_attr[\"name\"] == attr_name\n",
    "                        and item_attr[\"value\"] in attr_values\n",
    "                    ):\n",
    "                        curr_items.append(item)\n",
    "                        break\n",
    "\n",
    "            items = curr_items\n",
    "\n",
    "    return items\n",
    "\n",
    "\n",
    "results = retrieve_and_filter(test_query, table, generated_filter)\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Retrieval\n",
    "\n",
    "We want to evaluate the retrieval performance of our model. To do so, we'll generate some synthetic queries that require the use of metadata filtering and evaluate the recall and MRR of our model before and after employing these filters.\n",
    "\n",
    "We want to use the same queries because that gives us an easy way to compare against the initial baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./queries.json\") as f:\n",
    "    queries = [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-5-1733716386 is running at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733716386\n",
      "query-generation (data): 38it [00:00, 76626.71it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12738728eef14566998ee423e970c0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "query-generation (tasks):   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-5-1733716386 compared to week-5-1733716192:\n",
      "84.21% 'mrr@1'     score\n",
      "87.72% 'mrr@3'     score\n",
      "88.25% 'mrr@5'     score\n",
      "88.95% 'mrr@10'    score\n",
      "88.95% 'mrr@15'    score\n",
      "88.95% 'mrr@25'    score\n",
      "84.21% 'recall@1'  score\n",
      "92.11% 'recall@3'  score\n",
      "94.74% 'recall@5'  score\n",
      "100.00% 'recall@10' score\n",
      "100.00% 'recall@15' score\n",
      "100.00% 'recall@25' score\n",
      "\n",
      "14.09s (+1083.56%) 'duration'\t(1 improvements, 37 regressions)\n",
      "\n",
      "See results for week-5-1733716386 at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733716386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvalResultWithSummary(summary=\"...\", results=[...])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from braintrust import Eval, Score\n",
    "from helpers import get_metrics_at_k\n",
    "import instructor\n",
    "import openai\n",
    "\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    metrics = get_metrics_at_k(metrics=[\"mrr\", \"recall\"], sizes=[1, 3, 5, 10, 15, 25])\n",
    "    return [\n",
    "        Score(\n",
    "            name=metric,\n",
    "            score=score_fn(output, kwargs[\"expected\"]),\n",
    "            metadata={\"query\": input, \"result\": output, **kwargs[\"metadata\"]},\n",
    "        )\n",
    "        for metric, score_fn in metrics.items()\n",
    "    ]\n",
    "\n",
    "\n",
    "client = instructor.from_openai(openai.AsyncOpenAI())\n",
    "taxonomy_data = process_taxonomy_file(\"taxonomy.yml\")\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "table = db.open_table(\"labelled_items\")\n",
    "\n",
    "\n",
    "async def generate_filters_and_retrieve_items(query: dict, hooks) -> dict:\n",
    "    filters = await extract_query_filters(query[\"query\"], client, taxonomy_data)\n",
    "    hooks.meta(filters=filters.model_dump(), item=query[\"id\"])\n",
    "\n",
    "    return [item[\"id\"] for item in retrieve_and_filter(query[\"query\"], table, filters)]\n",
    "\n",
    "\n",
    "await Eval(\n",
    "    \"query-generation\",\n",
    "    data=lambda: [{\"input\": query, \"expected\": [query[\"id\"]]} for query in queries],\n",
    "    task=generate_filters_and_retrieve_items,\n",
    "    scores=[evaluate_braintrust],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Results Analysis\n",
    "\n",
    "We can see that the structured metadata extraction approach shows strong performance on both MRR (Mean Reciprocal Rank) and Recall metrics. More concretely, we see that recall@5,10,15 and mrr@5,10,15 show an improvement of ~18-20% on average.\n",
    "\n",
    "With metadata filtering, we're able to retrieve more relevant items and consequently, rank them higher since we remove the irrelevant items. This is evidenced by the recall@10 of 0.87 which is higher than the recall@25 of semantic search which is 0.84.\n",
    "\n",
    "This demonstrates that structured metadata extraction is an effective approach for product search and filtering. In the next portion, we'll look at how we can improve on retrieval performance by improving the captioning of our images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Captioning\n",
    "\n",
    "We can improve on the retrieval performance by improving the captioning of our images. Previously what we did was to simply embed the description of the text itself but we can do better by concatenating and adding in metadata such as price, category, subcategory and occasions before embedding it.\n",
    "\n",
    "Let's see how this impacts our retrieval performance. We'll do so in 2 steps\n",
    "\n",
    "1. First, we'll re-ingest our data so that we use our new formatted text\n",
    "2. Secondly, we'll then benchmark our retrieval against the original description that we embedded\n",
    "\n",
    "We'll use recall and mrr to quantify the improvement as usual with k = [1,3,5,10,15,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=768x1024>,\n",
       " 'title': 'Lace Detail Sleeveless Top',\n",
       " 'brand': 'H&M',\n",
       " 'description': \"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace detailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day comfort.\",\n",
       " 'category': 'Women',\n",
       " 'subcategory': 'Tops',\n",
       " 'product_type': 'Tank Tops',\n",
       " 'attributes': '[{\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"}, {\"name\": \"Neckline\", \"value\": \"Crew Neck\"}]',\n",
       " 'material': 'Cotton',\n",
       " 'pattern': 'Solid',\n",
       " 'id': 1,\n",
       " 'price': 181.04,\n",
       " 'occasions': '[\"Everyday Wear\", \"Casual Outings\", \"Smart Casual\", \"Dinner Dates\", \"Partywear\"]'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = [item for item in load_dataset(\"ivanleomk/labelled-ecommerce-taxonomy\")[\"train\"]]\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">title: Lace Detail Sleeveless Top\n",
       "description: Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace detailing at \n",
       "the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day comfort.\n",
       "brand: H&amp;M\n",
       "category: Women\n",
       "subcategory: Tops\n",
       "product_type: Tank Tops\n",
       "price: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">181.04</span>\n",
       "occasions: Everyday Wear,Casual Outings,Smart Casual,Dinner Dates,Partywear\n",
       "attributes: Sleeve Length: Sleeveless\n",
       "  -Neckline: Crew Neck\n",
       "</pre>\n"
      ],
      "text/plain": [
       "title: Lace Detail Sleeveless Top\n",
       "description: Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace detailing at \n",
       "the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day comfort.\n",
       "brand: H&M\n",
       "category: Women\n",
       "subcategory: Tops\n",
       "product_type: Tank Tops\n",
       "price: \u001b[1;36m181.04\u001b[0m\n",
       "occasions: Everyday Wear,Casual Outings,Smart Casual,Dinner Dates,Partywear\n",
       "attributes: Sleeve Length: Sleeveless\n",
       "  -Neckline: Crew Neck\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "from rich import print\n",
    "import json\n",
    "\n",
    "\n",
    "def format_text(item):\n",
    "    attributes = json.loads(item[\"attributes\"])\n",
    "    attributes_str = \"\\n  -\".join(\n",
    "        [f\"{attr['name']}: {attr['value']}\" for attr in attributes]\n",
    "    )\n",
    "    return f\"\"\"\n",
    "title: {item['title']}\n",
    "description: {item['description']}\n",
    "brand: {item['brand']}\n",
    "category: {item['category']}\n",
    "subcategory: {item['subcategory']}\n",
    "product_type: {item['product_type']}\n",
    "price: {item['price']}\n",
    "occasions: {','.join(json.loads(item['occasions']))}\n",
    "attributes: {attributes_str}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "print(format_text(ds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lancedb.pydantic import LanceModel, Vector\n",
    "import lancedb\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "\n",
    "# Create Embedding Function\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "# Define a Model that will be used as the schema for our collection\n",
    "class ItemWithConcatendatedDescription(LanceModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    description: str\n",
    "    text: str = func.SourceField()\n",
    "    brand: str\n",
    "    category: str\n",
    "    subcategory: str\n",
    "    product_type: str\n",
    "    attributes: str\n",
    "    occasions:str\n",
    "    material: str\n",
    "    pattern: str\n",
    "    price: float\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "table_name = \"concat_items\"\n",
    "\n",
    "# if table_name not in db.table_names():\n",
    "if True:\n",
    "    concat_items = db.create_table(\n",
    "        table_name, schema=ItemWithConcatendatedDescription, mode=\"overwrite\"\n",
    "    )\n",
    "    entries = []\n",
    "    for row in ds:\n",
    "        entries.append(\n",
    "            {\n",
    "                \"id\": row[\"id\"],\n",
    "                \"title\": row[\"title\"],\n",
    "                \"description\": row[\"description\"],\n",
    "                \"brand\": row[\"brand\"],\n",
    "                \"category\": row[\"category\"],\n",
    "                \"subcategory\": row[\"subcategory\"],\n",
    "                \"product_type\": row[\"product_type\"],\n",
    "                \"attributes\": row[\"attributes\"],\n",
    "                \"material\": row[\"material\"],\n",
    "                \"pattern\": row[\"pattern\"],\n",
    "                \"price\": row[\"price\"],\n",
    "                \"text\": format_text(row),\n",
    "                \"occasions\": row[\"occasions\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    concat_items.add(entries)\n",
    "\n",
    "concat_table = db.open_table(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see the impact of the better captioning on the retrieval performance. Therefore we can just run the same evaluation as before but on a differernt table or wherever you plan to store your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "queries = [json.loads(row) for row in open(\"./queries.json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-5-1733714087 is running at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733714087\n",
      "query-generation (data): 38it [00:00, 51150.05it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e9492220484f73933ecb7c887b5186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "query-generation (tasks):   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-5-1733714087 compared to week-5-1733713979:\n",
      "39.47% (+39.47%) 'mrr@1'     score\t(0 improvements, 0 regressions)\n",
      "45.61% (+45.61%) 'mrr@3'     score\t(0 improvements, 0 regressions)\n",
      "47.19% (+47.19%) 'mrr@5'     score\t(0 improvements, 0 regressions)\n",
      "48.98% (+48.98%) 'mrr@10'    score\t(0 improvements, 0 regressions)\n",
      "49.16% (+49.16%) 'mrr@15'    score\t(1 improvements, 0 regressions)\n",
      "49.47% (+49.47%) 'mrr@25'    score\t(2 improvements, 0 regressions)\n",
      "39.47% (+39.47%) 'recall@1'  score\t(0 improvements, 0 regressions)\n",
      "55.26% (+55.26%) 'recall@3'  score\t(0 improvements, 0 regressions)\n",
      "63.16% (+63.16%) 'recall@5'  score\t(0 improvements, 0 regressions)\n",
      "76.32% (+76.32%) 'recall@10' score\t(0 improvements, 0 regressions)\n",
      "78.95% (+78.95%) 'recall@15' score\t(1 improvements, 0 regressions)\n",
      "84.21% (+84.21%) 'recall@25' score\t(2 improvements, 0 regressions)\n",
      "\n",
      "0.88s (-998.88%) 'duration'\t(38 improvements, 0 regressions)\n",
      "\n",
      "See results for week-5-1733714087 at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733714087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-5-1733714098 is running at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733714098\n",
      "query-generation (data): 38it [00:00, 168838.51it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a277b5c1a82430dafefb2fb191d7021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "query-generation (tasks):   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-5-1733714098 compared to week-5-1733714087:\n",
      "52.63% (+13.16%) 'mrr@1'     score\t(6 improvements, 1 regressions)\n",
      "56.14% (+10.53%) 'mrr@3'     score\t(8 improvements, 2 regressions)\n",
      "58.64% (+11.45%) 'mrr@5'     score\t(11 improvements, 3 regressions)\n",
      "60.31% (+11.33%) 'mrr@10'    score\t(13 improvements, 5 regressions)\n",
      "60.55% (+11.38%) 'mrr@15'    score\t(13 improvements, 6 regressions)\n",
      "60.97% (+11.49%) 'mrr@25'    score\t(14 improvements, 7 regressions)\n",
      "52.63% (+13.16%) 'recall@1'  score\t(6 improvements, 1 regressions)\n",
      "60.53% (+05.26%) 'recall@3'  score\t(4 improvements, 2 regressions)\n",
      "71.05% (+07.89%) 'recall@5'  score\t(5 improvements, 2 regressions)\n",
      "84.21% (+07.89%) 'recall@10' score\t(4 improvements, 1 regressions)\n",
      "86.84% (+07.89%) 'recall@15' score\t(4 improvements, 1 regressions)\n",
      "94.74% (+10.53%) 'recall@25' score\t(4 improvements, 0 regressions)\n",
      "\n",
      "0.72s (-16.06%) 'duration'\t(33 improvements, 5 regressions)\n",
      "\n",
      "See results for week-5-1733714098 at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733714098\n"
     ]
    }
   ],
   "source": [
    "from braintrust import Eval, Score\n",
    "from helpers import get_metrics_at_k\n",
    "\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    metrics = get_metrics_at_k(metrics=[\"mrr\", \"recall\"], sizes=[1, 3, 5, 10, 15, 25])\n",
    "    return [\n",
    "        Score(\n",
    "            name=metric,\n",
    "            score=score_fn(output, kwargs[\"expected\"]),\n",
    "            metadata={\"query\": input, \"result\": output, **kwargs[\"metadata\"]},\n",
    "        )\n",
    "        for metric, score_fn in metrics.items()\n",
    "    ]\n",
    "\n",
    "\n",
    "def retrieve_items(query: str, table, hooks):\n",
    "    # Search using the query text\n",
    "    results = table.search(query).limit(25).to_list()\n",
    "\n",
    "    hooks.meta(\n",
    "        query=query,\n",
    "        items=[\n",
    "            {**{k: v for k, v in item.items() if k not in [\"vector\", \"image\"]}}\n",
    "            for item in results\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return [item[\"id\"] for item in results]\n",
    "\n",
    "tables = [db.open_table(\"items\"), db.open_table(\"concat_items\")]\n",
    "\n",
    "results = []\n",
    "\n",
    "for query_table in tables:\n",
    "    results.append(\n",
    "        await Eval(\n",
    "            \"query-generation\",\n",
    "            data=lambda: [\n",
    "                {\"input\": query[\"query\"], \"expected\": [query[\"id\"]]}\n",
    "                for query in queries\n",
    "            ],\n",
    "            task=lambda query, hooks: retrieve_items(query, query_table, hooks),\n",
    "            scores=[evaluate_braintrust],\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we were to combine this with our metadata filtering approach - we can see that we get an increase of ~10-15% in recall for MRR and ~30% increase in recall. Notice how recall@25 has an absolute increase of ~5% which means that with the new filters, we're surfacing new relevant items that didn't apppear in the top 25 items before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-5-1733716464 is running at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733716464\n",
      "query-generation (data): 38it [00:00, 89240.51it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6657834633584ec6a6f49cea2d42d5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "query-generation (tasks):   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-5-1733716464 compared to week-5-1733716430:\n",
      "84.21% 'mrr@1'     score\n",
      "87.72% 'mrr@3'     score\n",
      "87.72% 'mrr@5'     score\n",
      "88.75% 'mrr@10'    score\n",
      "88.75% 'mrr@15'    score\n",
      "88.75% 'mrr@25'    score\n",
      "84.21% 'recall@1'  score\n",
      "92.11% 'recall@3'  score\n",
      "92.11% 'recall@5'  score\n",
      "100.00% 'recall@10' score\n",
      "100.00% 'recall@15' score\n",
      "100.00% 'recall@25' score\n",
      "\n",
      "16.69s (+1432.90%) 'duration'\t(1 improvements, 37 regressions)\n",
      "\n",
      "See results for week-5-1733716464 at https://www.braintrust.dev/app/567/p/query-generation/experiments/week-5-1733716464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvalResultWithSummary(summary=\"...\", results=[...])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "async def generate_filters_and_retrieve_items(query: dict, hooks) -> dict:\n",
    "    filters = await extract_query_filters(query[\"query\"], client, taxonomy_data)\n",
    "    hooks.meta(filters=filters.model_dump(), item=query)\n",
    "\n",
    "    return [item[\"id\"] for item in retrieve_and_filter(query[\"query\"], concat_table, filters)]\n",
    "\n",
    "\n",
    "await Eval(\n",
    "    \"query-generation\",\n",
    "    data=lambda: [\n",
    "        {\"input\": query, \"expected\": [query[\"id\"]]}\n",
    "        for query in queries\n",
    "    ],\n",
    "    task=generate_filters_and_retrieve_items,\n",
    "    scores=[evaluate_braintrust],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric     | Description | Concatenated Info | Concatenated + Query Understanding |\n",
    "|------------|-------------|-------------------|-----------------------------------|\n",
    "| **mrr@1**  | 0.39 | 0.53 (+35.9%) | 0.84 (+115.4%) |\n",
    "| **mrr@3**  | 0.46 | 0.56 (+21.7%) | 0.88 (+91.3%) |\n",
    "| **mrr@5**  | 0.47 | 0.59 (+25.5%) | 0.88 (+87.2%) |\n",
    "| **mrr@10** | 0.49 | 0.60 (+22.4%) | 0.89 (+81.6%) |\n",
    "| **mrr@15** | 0.49 | 0.61 (+24.5%) | 0.89 (+81.6%) |\n",
    "| **mrr@25** | 0.49 | 0.61 (+24.5%) | 0.89 (+81.6%) |\n",
    "| **recall@1**  | 0.39 | 0.53 (+35.9%) | 0.84 (+115.4%) |\n",
    "| **recall@3**  | 0.55 | 0.61 (+10.9%) | 0.92 (+67.3%) |\n",
    "| **recall@5**  | 0.63 | 0.71 (+12.7%) | 0.92 (+46.0%) |\n",
    "| **recall@10** | 0.76 | 0.84 (+10.5%) | 1.00 (+31.6%) |\n",
    "| **recall@15** | 0.79 | 0.87 (+10.1%) | 1.00 (+26.6%) |\n",
    "| **recall@25** | 0.84 | 0.95 (+13.1%) | 1.00 (+19.0%) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we can roughly see we get a ~26% increase in mrr  and ~12% increase on average for recall across different values of k when we modify the captioning of our images and items. When combined with metadata filtering, we get a significant boost in recall@25 to 1.\n",
    "\n",
    "This is huge because we didn't have to do anything other than to modify the text chunk that we embedded. \n",
    "\n",
    "It's important here to note that the reason why we can do so is because we started off with an objective set of metrics ( MRR and Recall ) which made it easy to compare across different retrieval methods. \n",
    "\n",
    "By basing our retrieval and Language Model applications on a solid set of retrieval metrics, we're able to experiment and compare different approaches, before conclusively determining what makes the most sense for our use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we'll look at how we can combine structured extraction with some simple text-2-sql in order to take action on what users prefer and want. That will also be a quick sneak peek into week6 where we'll be looking at how to nail down function calling in greater detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
